# Assessment Microcopy Draft

These prompts follow the condensed Magician/Sage/Creator cadence: the **Prompt** delivers a concise story-starter; the **Helper Text** offers practical insight/application detail for busy innovation leaders. Ratings use the 1 (nascent) to 5 (leading) maturity scale.

---

## Healthcare

### Strategy & Leadership
- **Prompt:** When your executive team describes AI’s role in patient care, how vivid and actionable is that story?
- **Helper Text:** 1 = exploratory slides without funding; 5 = a financed, cross-functional roadmap that links AI initiatives to measurable clinical, financial, and equity outcomes.

### People & Culture
- **Prompt:** How ready are clinicians and staff to co-create outcomes with AI rather than work around it?
- **Helper Text:** Consider recruitment, ongoing training, and ethics forums. 1 = isolated champions; 5 = organization-wide fluency with incentives tied to responsible adoption.

### Architecture & Governance
- **Prompt:** Can you trace sensitive health data from source to sanctioned AI deployment without gaps?
- **Helper Text:** 1 = ad hoc integrations and manual reviews; 5 = policy-driven pipelines audited for HIPAA, security, and model risk on a recurring cadence.

### Product Management
- **Prompt:** How tightly do you weave AI enhancements into new care pathways or service-line launches?
- **Helper Text:** 1 = AI ideas explored after rollout; 5 = dedicated product owners who co-plan AI and clinical delivery, with stage gates tied to patient impact.

### User Experience & Ethics
- **Prompt:** How confident are patients and providers that AI-enabled experiences respect consent, clarity, and compassion?
- **Helper Text:** 1 = limited transparency into AI touchpoints; 5 = co-designed journeys with bias monitoring, escalation paths, and clear patient communications.

### Data Sourcing
- **Prompt:** How complete and timely is the data that feeds your AI—from EHR to social determinants?
- **Helper Text:** 1 = siloed datasets refreshed manually; 5 = governed ingestion across clinical, operational, and partner feeds with traceable provenance.

### Data Operations
- **Prompt:** How resilient are the pipelines that deliver trusted data to analytics and AI teams?
- **Helper Text:** 1 = frequent downtime and manual restarts; 5 = automated quality checks, SLA monitoring, and proactive issue resolution across environments.

### Analytics
- **Prompt:** How routinely do leaders make decisions with near-real-time insight into population, financial, and operational metrics?
- **Helper Text:** 1 = retrospective reporting; 5 = predictive dashboards embedded in governance forums and frontline workflows.

### Using AI Products
- **Prompt:** How broadly do teams rely on proven third-party AI solutions for clinical and operational tasks?
- **Helper Text:** 1 = limited pilots; 5 = enterprise-wide adoption with measured ROI, change management, and integration into standard procedures.

### Building AI Products
- **Prompt:** How mature is your in-house ability to design, validate, and deploy clinical-grade AI?
- **Helper Text:** 1 = ad hoc prototypes; 5 = regulated pipelines with clinical validation, monitoring, and post-market surveillance.

### Customers’ AI Products
- **Prompt:** How effectively do patient- or partner-facing AI experiences build trust and measurable value?
- **Helper Text:** 1 = experimental self-service tools; 5 = personalized experiences with clear opt-ins, outcome tracking, and continuous improvement.

---

## Legal

### Strategy & Leadership
- **Prompt:** When firm leadership speaks about AI, how clearly do they link it to winning and retaining clients?
- **Helper Text:** 1 = aspirational presentations; 5 = financed portfolio of AI initiatives mapped to practice growth, profitability, and risk mitigation.

### People & Culture
- **Prompt:** How ready are partners, associates, and staff to incorporate AI into matter strategy and client service?
- **Helper Text:** 1 = optional trainings with low uptake; 5 = formal capability plans, incentives, and ethical guardrails embedded in performance reviews.

### Architecture & Governance
- **Prompt:** Can you evidence how confidential matter data flows through AI systems with privilege intact?
- **Helper Text:** 1 = scattered repositories and manual controls; 5 = governed pipelines with audit trails, access policies, and model risk reviews tailored to legal confidentiality.

### Product Management
- **Prompt:** How consistently do you design AI-enabled services alongside new offerings or alternative fee arrangements?
- **Helper Text:** 1 = AI considered post-launch; 5 = product leaders co-develop client journeys, pricing, and AI features with stakeholder sign-off.

### User Experience & Ethics
- **Prompt:** How confident are clients that your AI-assisted advice is transparent, unbiased, and defensible?
- **Helper Text:** 1 = minimal disclosure of AI involvement; 5 = codified communication standards, bias testing, and escalation paths for ethical concerns.

### Data Sourcing
- **Prompt:** How comprehensive is the data foundation feeding AI—from matter histories to external research and regulatory updates?
- **Helper Text:** 1 = fragmented knowledge bases; 5 = curated, tagged, and permissioned datasets refreshed through automated pipelines.

### Data Operations
- **Prompt:** How resilient are the systems delivering accurate data to case teams, pricing, and knowledge management?
- **Helper Text:** 1 = manual exports and frequent delays; 5 = automated monitoring, quality alerts, and version-controlled repositories.

### Analytics
- **Prompt:** How often do practice leaders rely on analytics for staffing, pricing, and client strategy decisions?
- **Helper Text:** 1 = sporadic backward-looking reports; 5 = predictive dashboards embedded in matter intake, pricing committees, and client reviews.

### Using AI Products
- **Prompt:** How pervasively do teams employ vetted third-party AI tools for research, drafting, or discovery?
- **Helper Text:** 1 = isolated pilots; 5 = firm-wide rollouts with governance, training, and measurable efficiency gains.

### Building AI Products
- **Prompt:** How capable are you at crafting proprietary AI workflows or copilots tailored to firm expertise?
- **Helper Text:** 1 = concept decks; 5 = secure development lifecycle with attorney validation, risk assessments, and controlled releases.

### Customers’ AI Products
- **Prompt:** How effectively do client-facing AI experiences—portals, advisors, self-service tools—enhance trust and outcomes?
- **Helper Text:** 1 = experimental tools without adoption metrics; 5 = co-designed experiences with clients, usage analytics, and continuous improvement roadmaps.

